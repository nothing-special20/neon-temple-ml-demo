{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca49e079",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import PromptTemplate, LLMChain\n",
    "import os\n",
    "import json\n",
    "import re\n",
    "import docx\n",
    "\n",
    "def env_vars():\n",
    "    with open('.env', 'r') as f:\n",
    "        lines = f.readlines()\n",
    "    \n",
    "    lines = [re.sub('\"|\\n', '', x) for x in lines]\n",
    "    lines = [{x.split('=')[0]: x.split('=')[1]} for x in lines]\n",
    "\n",
    "    env_object = {}\n",
    "    for json_ in lines:\n",
    "        for key, value in json_.items():\n",
    "            env_object[key] = value\n",
    "\n",
    "    return env_object\n",
    "\n",
    "ENV_VARS = env_vars()\n",
    "OPEN_AI_KEY=ENV_VARS['OPEN_AI_KEY']\n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = OPEN_AI_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0cd06d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_string(s, chunk_size):\n",
    "    # Split the string into words\n",
    "    words = s.split()\n",
    "\n",
    "    # Create chunks of words\n",
    "    chunks = [words[i:i + chunk_size] for i in range(0, len(words), chunk_size)]\n",
    "\n",
    "    # Join the chunks back into strings\n",
    "    return [' '.join(chunk) for chunk in chunks]\n",
    "\n",
    "def create_table_of_contents(sampled_text):\n",
    "    create_topics_template = \"\"\"\n",
    "        Question: Please Create a table of contents, with section titles summarizing chunks of text. Each section will start with a number (1-5) (at most 5 sections), and each section description should be less than 50 characters, for this text: {text}.\n",
    "\n",
    "        Please return the response as a json object, where the key is the first 40 chars of the sentence where the section starts, and the value is the section title. \n",
    "        \n",
    "        Answer: Here is the response json object:\n",
    "    \"\"\"\n",
    "    openai_llm = OpenAI(verbose=True, temperature=.1, model_name=\"text-davinci-003\")\n",
    "    simple_prompt = PromptTemplate(input_variables=[\"text\"], template=create_topics_template)\n",
    "    chain = LLMChain(llm=openai_llm, prompt=simple_prompt)\n",
    "    table_of_contents = chain.run(sampled_text)\n",
    "    table_of_contents = json.loads(table_of_contents)\n",
    "\n",
    "    print(table_of_contents)\n",
    "\n",
    "    #\n",
    "    new_table_of_contents = {}\n",
    "\n",
    "    counter = 0\n",
    "    for x in table_of_contents.items():\n",
    "        if counter == 0:\n",
    "            new_table_of_contents[x[0]] = x[1] + '\\n\\n' + x[0]\n",
    "\n",
    "        else:\n",
    "            new_table_of_contents[x[0]] = '\\n\\n' + x[1] + '\\n\\n' + x[0]\n",
    "\n",
    "        counter += 1\n",
    "    \n",
    "    return new_table_of_contents\n",
    "\n",
    "#write a function to write text to a word docx file\n",
    "def write_to_word(text, filename):\n",
    "    doc = docx.Document()\n",
    "    doc.add_paragraph(text)\n",
    "    doc.save(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "717a939f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/transformers/generation/utils.py:1346: UserWarning: Using `max_length`'s default (448) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "file = \"input_data/Florida Gov. Ron DeSantis Vows 'No More Socialism For The Wealthy' During Economic Speech.mp4\"\n",
    "# file = \"FULL SPEECH _ Presidential candidate Ron Desantis at NC GOP Convention.mp4\"\n",
    "\n",
    "pipe = pipeline(\n",
    "  \"automatic-speech-recognition\",\n",
    "  model=\"openai/whisper-large-v2\",\n",
    "  chunk_length_s=30,\n",
    "  device=\"cpu\",\n",
    ")\n",
    "\n",
    "prediction = pipe(file, batch_size=8)[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff7f318",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prediction' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m speech_chunks \u001b[39m=\u001b[39m chunk_string(prediction, \u001b[39m600\u001b[39m)\n\u001b[1;32m      2\u001b[0m toc_list \u001b[39m=\u001b[39m [create_table_of_contents(x) \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m speech_chunks[\u001b[39m0\u001b[39m:\u001b[39m3\u001b[39m]]\n\u001b[1;32m      3\u001b[0m toc_list\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prediction' is not defined"
     ]
    }
   ],
   "source": [
    "speech_chunks = chunk_string(prediction, 600)\n",
    "toc_list = [create_table_of_contents(x) for x in speech_chunks[0:3]]\n",
    "toc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df6458a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Number nine Ensure that bad economic': 'Economic Policy\\n\\nNumber nine Ensure that bad economic',\n",
       " 'Part of having a good economy is that': 'Cycles in the Economy\\n\\nPart of having a good economy is that',\n",
       " 'Of course, the people that are not': 'Elites Bailed Out\\n\\nOf course, the people that are not',\n",
       " \"We know that that's not the case.\": \"No Bailouts\\n\\nWe know that that's not the case.\",\n",
       " 'And finally, number 10, we need to': \"Congress's Spending Habits\\n\\nAnd finally, number 10, we need to\"}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ae22ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Number nine Ensure that bad economic': 'Bad Economic Actors Held Responsible', 'Part of having a good economy is': 'Good Economy Has Cycles', 'When elites get bailed out from': 'Elites Bailed Out Distorts Economy', 'And finally, number 10, we need': \"Rein In Congress's Spending Habits\", 'So at the end of the day, economic': 'Economic Policy Beyond Dollars & Cents'}\n"
     ]
    }
   ],
   "source": [
    "speech_chunks = chunk_string(prediction, 600)\n",
    "_test = create_table_of_contents(speech_chunks[0])\n",
    "_test\n",
    "\n",
    "test_chunk = speech_chunks[0]\n",
    "test_chunk\n",
    "\n",
    "for x in _test.items():\n",
    "    test_chunk = re.sub(x[0], x[1], test_chunk)\n",
    "\n",
    "test_chunk\n",
    "\n",
    "write_to_word(test_chunk, 'test_chunk.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "5956b2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Number nine Ensure that bad economic': 'Bad Economic Actors Held Responsible', 'Part of having a good economy is that': 'Good Economy Has Cycles', 'When elites get bailed out from their': 'Elites Bailed Out from Bad Decisions', 'And finally, number 10, we need to': \"Rein in Congress's Spending Habits\", 'So at the end of the day, economic': 'Economic Policy Beyond Dollars & Cents'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'Number nine Ensure that bad economic': 'Bad Economic Actors Held Responsible\\n\\nNumber nine Ensure that bad economic',\n",
       " 'Part of having a good economy is that': '\\n\\nGood Economy Has Cycles\\n\\nPart of having a good economy is that',\n",
       " 'When elites get bailed out from their': '\\n\\nElites Bailed Out from Bad Decisions\\n\\nWhen elites get bailed out from their',\n",
       " 'And finally, number 10, we need to': \"\\n\\nRein in Congress's Spending Habits\\n\\nAnd finally, number 10, we need to\",\n",
       " 'So at the end of the day, economic': '\\n\\nEconomic Policy Beyond Dollars & Cents\\n\\nSo at the end of the day, economic'}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_test = create_table_of_contents(speech_chunks[0])\n",
    "_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "76b0e495",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m pdf\u001b[39m.\u001b[39madd_page()\n\u001b[1;32m      5\u001b[0m pdf\u001b[39m.\u001b[39mset_font(\u001b[39m\"\u001b[39m\u001b[39mArial\u001b[39m\u001b[39m\"\u001b[39m, size \u001b[39m=\u001b[39m \u001b[39m15\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m pdf\u001b[39m.\u001b[39;49mcell(\u001b[39m200\u001b[39;49m, \u001b[39m10\u001b[39;49m, txt \u001b[39m=\u001b[39;49m _test, ln \u001b[39m=\u001b[39;49m \u001b[39m1\u001b[39;49m, align \u001b[39m=\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39mC\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      7\u001b[0m pdf\u001b[39m.\u001b[39moutput(\u001b[39m\"\u001b[39m\u001b[39mYouTubeSpeech.pdf\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fpdf/fpdf.py:150\u001b[0m, in \u001b[0;36mFPDF.check_page.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39merror(\u001b[39m\"\u001b[39m\u001b[39mNo page open, you need to call add_page() first\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    149\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m     \u001b[39mreturn\u001b[39;00m fn(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fpdf/fpdf.py:726\u001b[0m, in \u001b[0;36mFPDF.cell\u001b[0;34m(self, w, h, txt, border, ln, align, fill, link)\u001b[0m\n\u001b[1;32m    724\u001b[0m     dx\u001b[39m=\u001b[39mw\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_margin\u001b[39m-\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_string_width(txt)\n\u001b[1;32m    725\u001b[0m \u001b[39melif\u001b[39;00m(align\u001b[39m==\u001b[39m\u001b[39m'\u001b[39m\u001b[39mC\u001b[39m\u001b[39m'\u001b[39m):\n\u001b[0;32m--> 726\u001b[0m     dx\u001b[39m=\u001b[39m(w\u001b[39m-\u001b[39m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_string_width(txt))\u001b[39m/\u001b[39m\u001b[39m2.0\u001b[39m\n\u001b[1;32m    727\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m     dx\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mc_margin\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/fpdf/fpdf.py:366\u001b[0m, in \u001b[0;36mFPDF.get_string_width\u001b[0;34m(self, s)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, l):\n\u001b[0;32m--> 366\u001b[0m         w \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m cw\u001b[39m.\u001b[39mget(s[i],\u001b[39m0\u001b[39m)\n\u001b[1;32m    367\u001b[0m \u001b[39mreturn\u001b[39;00m w\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfont_size\u001b[39m/\u001b[39m\u001b[39m1000.0\u001b[39m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "#write text to a pdf file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
